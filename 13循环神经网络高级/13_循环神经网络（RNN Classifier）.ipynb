{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abde7ae",
   "metadata": {},
   "source": [
    "核心问题在于，判断数据集中的每个名字所属的国家，共有18个国家类别。显然，每个国家或地区的人取名字都有其自己独特的语言习惯，因此可以利用RNN分析其名字（字符串）的潜在特点来进行分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dec26e",
   "metadata": {},
   "source": [
    "即序列依次经过嵌入层和RNN Cell后得到最终的隐藏状态$h_N$，利用最终的隐藏层状态通过一个线性层来进行一个18分类的多分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a471b05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The num of total training epochs is 100. \n",
      "time_elapsed:[0, 16.36416530609131], Epoch 0, [2560 / 13374] loss = 0.0013631109613925219\n",
      "time_elapsed:[0, 28.751747131347656], Epoch 0, [5120 / 13374] loss = 0.0005770277930423617\n",
      "time_elapsed:[0, 39.39106559753418], Epoch 0, [7680 / 13374] loss = 0.00033645748044364154\n",
      "time_elapsed:[0, 47.24814796447754], Epoch 0, [10240 / 13374] loss = 0.00023277479340322316\n",
      "time_elapsed:[0, 56.03964400291443], Epoch 0, [12800 / 13374] loss = 0.00017854846373666078\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 67.164 %\n",
      "\n",
      "time_elapsed:[1, 15.244706869125366], Epoch 1, [2560 / 13374] loss = 0.0008207075297832489\n",
      "time_elapsed:[1, 26.466368436813354], Epoch 1, [5120 / 13374] loss = 0.0003788569592870772\n",
      "time_elapsed:[1, 38.25314259529114], Epoch 1, [7680 / 13374] loss = 0.00022733185323886573\n",
      "time_elapsed:[1, 48.243932008743286], Epoch 1, [10240 / 13374] loss = 0.0001804227358661592\n",
      "time_elapsed:[1, 57.330976486206055], Epoch 1, [12800 / 13374] loss = 0.00014113735232967883\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 73.612 %\n",
      "\n",
      "time_elapsed:[2, 18.965824842453003], Epoch 2, [2560 / 13374] loss = 0.0007608904270455241\n",
      "time_elapsed:[2, 31.419694423675537], Epoch 2, [5120 / 13374] loss = 0.0003182409855071455\n",
      "time_elapsed:[2, 51.92018437385559], Epoch 2, [7680 / 13374] loss = 0.000230676683713682\n",
      "time_elapsed:[3, 4.414271354675293], Epoch 2, [10240 / 13374] loss = 0.00018030412320513278\n",
      "time_elapsed:[3, 16.59213948249817], Epoch 2, [12800 / 13374] loss = 0.00012468128988984972\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 78.104 %\n",
      "\n",
      "time_elapsed:[3, 34.110552072525024], Epoch 3, [2560 / 13374] loss = 0.0005397113272920251\n",
      "time_elapsed:[3, 42.83203864097595], Epoch 3, [5120 / 13374] loss = 0.00026232306845486164\n",
      "time_elapsed:[3, 55.18928384780884], Epoch 3, [7680 / 13374] loss = 0.00014460686361417174\n",
      "time_elapsed:[4, 6.674007415771484], Epoch 3, [10240 / 13374] loss = 0.00014244962949305773\n",
      "time_elapsed:[4, 16.589069366455078], Epoch 3, [12800 / 13374] loss = 9.564941137796268e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 79.552 %\n",
      "\n",
      "time_elapsed:[4, 35.20391607284546], Epoch 4, [2560 / 13374] loss = 0.0005201519234105945\n",
      "time_elapsed:[4, 44.45406651496887], Epoch 4, [5120 / 13374] loss = 0.0002259493776364252\n",
      "time_elapsed:[4, 53.90532159805298], Epoch 4, [7680 / 13374] loss = 0.0001587613223819062\n",
      "time_elapsed:[5, 5.400424242019653], Epoch 4, [10240 / 13374] loss = 0.0001002761855488643\n",
      "time_elapsed:[5, 16.379068851470947], Epoch 4, [12800 / 13374] loss = 0.00010524196841288358\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 81.239 %\n",
      "\n",
      "time_elapsed:[5, 41.7402024269104], Epoch 5, [2560 / 13374] loss = 0.0003697423671837896\n",
      "time_elapsed:[5, 54.34913635253906], Epoch 5, [5120 / 13374] loss = 0.00020855807815678418\n",
      "time_elapsed:[6, 9.349030017852783], Epoch 5, [7680 / 13374] loss = 0.00010846344957826659\n",
      "time_elapsed:[6, 21.52490997314453], Epoch 5, [10240 / 13374] loss = 0.0001057870831573382\n",
      "time_elapsed:[6, 32.9552264213562], Epoch 5, [12800 / 13374] loss = 8.366543625015765e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 82.045 %\n",
      "\n",
      "time_elapsed:[6, 58.534188747406006], Epoch 6, [2560 / 13374] loss = 0.0003266229177825153\n",
      "time_elapsed:[7, 10.896485328674316], Epoch 6, [5120 / 13374] loss = 0.00021632752032019198\n",
      "time_elapsed:[7, 19.018163919448853], Epoch 6, [7680 / 13374] loss = 0.00011155583342770115\n",
      "time_elapsed:[7, 31.62898898124695], Epoch 6, [10240 / 13374] loss = 0.00010999046207871288\n",
      "time_elapsed:[7, 44.3482620716095], Epoch 6, [12800 / 13374] loss = 8.589981734985486e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.045 %\n",
      "\n",
      "time_elapsed:[8, 8.186300039291382], Epoch 7, [2560 / 13374] loss = 0.0002904165303334594\n",
      "time_elapsed:[8, 24.36407780647278], Epoch 7, [5120 / 13374] loss = 0.0001522518286947161\n",
      "time_elapsed:[8, 48.5765175819397], Epoch 7, [7680 / 13374] loss = 0.00010987083805957809\n",
      "time_elapsed:[9, 9.684143304824829], Epoch 7, [10240 / 13374] loss = 8.715229341760278e-05\n",
      "time_elapsed:[9, 29.102959871292114], Epoch 7, [12800 / 13374] loss = 6.521296018036082e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.075 %\n",
      "\n",
      "time_elapsed:[10, 3.909520387649536], Epoch 8, [2560 / 13374] loss = 0.00025951917632482946\n",
      "time_elapsed:[10, 13.921117067337036], Epoch 8, [5120 / 13374] loss = 0.00016421191685367376\n",
      "time_elapsed:[10, 22.69772434234619], Epoch 8, [7680 / 13374] loss = 9.684352698968723e-05\n",
      "time_elapsed:[10, 30.088889122009277], Epoch 8, [10240 / 13374] loss = 8.867801807355136e-05\n",
      "time_elapsed:[10, 38.76945352554321], Epoch 8, [12800 / 13374] loss = 5.988853081362322e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.597 %\n",
      "\n",
      "time_elapsed:[10, 53.11415934562683], Epoch 9, [2560 / 13374] loss = 0.0003109552781097591\n",
      "time_elapsed:[11, 1.3320558071136475], Epoch 9, [5120 / 13374] loss = 0.0001437882165191695\n",
      "time_elapsed:[11, 12.129100322723389], Epoch 9, [7680 / 13374] loss = 7.22073091310449e-05\n",
      "time_elapsed:[11, 23.907712697982788], Epoch 9, [10240 / 13374] loss = 7.28091545170173e-05\n",
      "time_elapsed:[11, 36.245383977890015], Epoch 9, [12800 / 13374] loss = 5.299628173816018e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.328 %\n",
      "\n",
      "time_elapsed:[11, 54.65762948989868], Epoch 10, [2560 / 13374] loss = 0.00022615163470618427\n",
      "time_elapsed:[12, 5.902395963668823], Epoch 10, [5120 / 13374] loss = 0.00015411232016049325\n",
      "time_elapsed:[12, 16.4966299533844], Epoch 10, [7680 / 13374] loss = 6.931802636245266e-05\n",
      "time_elapsed:[12, 23.13413429260254], Epoch 10, [10240 / 13374] loss = 7.493676821468398e-05\n",
      "time_elapsed:[12, 31.528460025787354], Epoch 10, [12800 / 13374] loss = 4.9568490794626996e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.119 %\n",
      "\n",
      "time_elapsed:[12, 45.64562010765076], Epoch 11, [2560 / 13374] loss = 0.0002418803924228996\n",
      "time_elapsed:[12, 58.37004327774048], Epoch 11, [5120 / 13374] loss = 0.00012986446381546557\n",
      "time_elapsed:[13, 5.111720323562622], Epoch 11, [7680 / 13374] loss = 5.2316758228698745e-05\n",
      "time_elapsed:[13, 11.61969542503357], Epoch 11, [10240 / 13374] loss = 5.7158245908794925e-05\n",
      "time_elapsed:[13, 17.870625972747803], Epoch 11, [12800 / 13374] loss = 5.4127100156620145e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.522 %\n",
      "\n",
      "time_elapsed:[13, 30.16686177253723], Epoch 12, [2560 / 13374] loss = 0.00021945135085843503\n",
      "time_elapsed:[13, 37.277615547180176], Epoch 12, [5120 / 13374] loss = 0.00012132917618146166\n",
      "time_elapsed:[13, 49.54254078865051], Epoch 12, [7680 / 13374] loss = 4.502426600083709e-05\n",
      "time_elapsed:[14, 0.25447607040405273], Epoch 12, [10240 / 13374] loss = 5.9110250731464475e-05\n",
      "time_elapsed:[14, 13.392407894134521], Epoch 12, [12800 / 13374] loss = 4.069348506163806e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.716 %\n",
      "\n",
      "time_elapsed:[14, 26.504011631011963], Epoch 13, [2560 / 13374] loss = 0.0002429414016660303\n",
      "time_elapsed:[14, 34.21143865585327], Epoch 13, [5120 / 13374] loss = 6.33582312730141e-05\n",
      "time_elapsed:[14, 40.02261519432068], Epoch 13, [7680 / 13374] loss = 5.784095264971256e-05\n",
      "time_elapsed:[14, 45.20304822921753], Epoch 13, [10240 / 13374] loss = 5.202682223170996e-05\n",
      "time_elapsed:[14, 50.30362868309021], Epoch 13, [12800 / 13374] loss = 3.8406440580729395e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.597 %\n",
      "\n",
      "time_elapsed:[14, 59.258500814437866], Epoch 14, [2560 / 13374] loss = 0.00012503177276812494\n",
      "time_elapsed:[15, 5.135768890380859], Epoch 14, [5120 / 13374] loss = 7.762049790471792e-05\n",
      "time_elapsed:[15, 11.898262023925781], Epoch 14, [7680 / 13374] loss = 5.553142909775488e-05\n",
      "time_elapsed:[15, 18.48935341835022], Epoch 14, [10240 / 13374] loss = 4.116131458431482e-05\n",
      "time_elapsed:[15, 25.870808839797974], Epoch 14, [12800 / 13374] loss = 2.85499027086189e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.000 %\n",
      "\n",
      "time_elapsed:[15, 38.99788451194763], Epoch 15, [2560 / 13374] loss = 0.0001586432772455737\n",
      "time_elapsed:[15, 45.65205979347229], Epoch 15, [5120 / 13374] loss = 4.6859928261255845e-05\n",
      "time_elapsed:[15, 51.54896020889282], Epoch 15, [7680 / 13374] loss = 2.7497535484144464e-05\n",
      "time_elapsed:[15, 58.85373091697693], Epoch 15, [10240 / 13374] loss = 3.803981962846592e-05\n",
      "time_elapsed:[16, 5.815368175506592], Epoch 15, [12800 / 13374] loss = 3.0395343856071122e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.358 %\n",
      "\n",
      "time_elapsed:[16, 18.135492086410522], Epoch 16, [2560 / 13374] loss = 0.00010580676462268457\n",
      "time_elapsed:[16, 24.579697847366333], Epoch 16, [5120 / 13374] loss = 4.594838173943572e-05\n",
      "time_elapsed:[16, 31.884816884994507], Epoch 16, [7680 / 13374] loss = 3.663823372335173e-05\n",
      "time_elapsed:[16, 38.35872483253479], Epoch 16, [10240 / 13374] loss = 3.467906572041102e-05\n",
      "time_elapsed:[16, 45.88548016548157], Epoch 16, [12800 / 13374] loss = 2.345374559808988e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.537 %\n",
      "\n",
      "time_elapsed:[17, 4.260119438171387], Epoch 17, [2560 / 13374] loss = 0.0001277230476262048\n",
      "time_elapsed:[17, 10.617203712463379], Epoch 17, [5120 / 13374] loss = 6.0975718952249736e-05\n",
      "time_elapsed:[17, 16.458644151687622], Epoch 17, [7680 / 13374] loss = 4.510447979555465e-05\n",
      "time_elapsed:[17, 26.010323762893677], Epoch 17, [10240 / 13374] loss = 2.4185019356082194e-05\n",
      "time_elapsed:[17, 32.959320306777954], Epoch 17, [12800 / 13374] loss = 2.685283288883511e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.776 %\n",
      "\n",
      "time_elapsed:[17, 46.09579563140869], Epoch 18, [2560 / 13374] loss = 8.992735092760995e-05\n",
      "time_elapsed:[17, 53.49378252029419], Epoch 18, [5120 / 13374] loss = 6.689049041597173e-05\n",
      "time_elapsed:[18, 0.7081828117370605], Epoch 18, [7680 / 13374] loss = 3.7339683331083506e-05\n",
      "time_elapsed:[18, 41.47631049156189], Epoch 18, [10240 / 13374] loss = 1.6368379874620587e-05\n",
      "time_elapsed:[19, 17.515195846557617], Epoch 18, [12800 / 13374] loss = 1.8121259927283973e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.134 %\n",
      "\n",
      "time_elapsed:[19, 30.082141399383545], Epoch 19, [2560 / 13374] loss = 0.00010351976379752159\n",
      "time_elapsed:[19, 37.95415496826172], Epoch 19, [5120 / 13374] loss = 4.340859959484078e-05\n",
      "time_elapsed:[19, 45.99218130111694], Epoch 19, [7680 / 13374] loss = 3.5883662349078804e-05\n",
      "time_elapsed:[19, 52.197559118270874], Epoch 19, [10240 / 13374] loss = 2.0162804503343068e-05\n",
      "time_elapsed:[20, 2.2869017124176025], Epoch 19, [12800 / 13374] loss = 1.586874896020163e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.851 %\n",
      "\n",
      "time_elapsed:[20, 21.309035301208496], Epoch 20, [2560 / 13374] loss = 8.813517342787236e-05\n",
      "time_elapsed:[20, 29.443456649780273], Epoch 20, [5120 / 13374] loss = 3.539570025168359e-05\n",
      "time_elapsed:[20, 40.21382188796997], Epoch 20, [7680 / 13374] loss = 2.963836959679611e-05\n",
      "time_elapsed:[20, 49.61719226837158], Epoch 20, [10240 / 13374] loss = 2.66709212155547e-05\n",
      "time_elapsed:[21, 0.33998847007751465], Epoch 20, [12800 / 13374] loss = 1.9527167751220986e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.164 %\n",
      "\n",
      "time_elapsed:[21, 19.436420917510986], Epoch 21, [2560 / 13374] loss = 6.855840911157429e-05\n",
      "time_elapsed:[21, 29.409499645233154], Epoch 21, [5120 / 13374] loss = 3.263020334998146e-05\n",
      "time_elapsed:[21, 39.97894549369812], Epoch 21, [7680 / 13374] loss = 3.0627350497525185e-05\n",
      "time_elapsed:[21, 54.453617095947266], Epoch 21, [10240 / 13374] loss = 2.009755371545907e-05\n",
      "time_elapsed:[22, 5.108582258224487], Epoch 21, [12800 / 13374] loss = 1.5908841305645183e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.075 %\n",
      "\n",
      "time_elapsed:[22, 22.723453760147095], Epoch 22, [2560 / 13374] loss = 5.2679319196613505e-05\n",
      "time_elapsed:[22, 33.874582052230835], Epoch 22, [5120 / 13374] loss = 4.38958486483898e-05\n",
      "time_elapsed:[22, 45.79648470878601], Epoch 22, [7680 / 13374] loss = 1.962467285920866e-05\n",
      "time_elapsed:[22, 54.28389286994934], Epoch 22, [10240 / 13374] loss = 1.802310907805804e-05\n",
      "time_elapsed:[23, 0.9517598152160645], Epoch 22, [12800 / 13374] loss = 1.4500875295198057e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.075 %\n",
      "\n",
      "time_elapsed:[23, 15.28324556350708], Epoch 23, [2560 / 13374] loss = 3.703049151226878e-05\n",
      "time_elapsed:[23, 21.713531255722046], Epoch 23, [5120 / 13374] loss = 2.6835701646632515e-05\n",
      "time_elapsed:[23, 30.680994033813477], Epoch 23, [7680 / 13374] loss = 1.6360745576093905e-05\n",
      "time_elapsed:[23, 38.01960897445679], Epoch 23, [10240 / 13374] loss = 1.8702821762417443e-05\n",
      "time_elapsed:[23, 45.76804852485657], Epoch 23, [12800 / 13374] loss = 1.8143364286515862e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.239 %\n",
      "\n",
      "time_elapsed:[24, 3.369429588317871], Epoch 24, [2560 / 13374] loss = 7.11425527697429e-05\n",
      "time_elapsed:[24, 22.540805101394653], Epoch 24, [5120 / 13374] loss = 3.1774503440828994e-05\n",
      "time_elapsed:[24, 37.28610944747925], Epoch 24, [7680 / 13374] loss = 2.8364336685626768e-05\n",
      "time_elapsed:[24, 47.811129093170166], Epoch 24, [10240 / 13374] loss = 1.6255618902505375e-05\n",
      "time_elapsed:[25, 1.2199196815490723], Epoch 24, [12800 / 13374] loss = 1.3579619917436503e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.776 %\n",
      "\n",
      "time_elapsed:[25, 18.86555051803589], Epoch 25, [2560 / 13374] loss = 4.2400442907819524e-05\n",
      "time_elapsed:[25, 25.43309187889099], Epoch 25, [5120 / 13374] loss = 2.382255843258463e-05\n",
      "time_elapsed:[25, 32.52132725715637], Epoch 25, [7680 / 13374] loss = 1.7455073248129338e-05\n",
      "time_elapsed:[25, 38.3316113948822], Epoch 25, [10240 / 13374] loss = 1.1581616490730084e-05\n",
      "time_elapsed:[25, 45.29948592185974], Epoch 25, [12800 / 13374] loss = 1.1694248314597644e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.955 %\n",
      "\n",
      "time_elapsed:[25, 58.36188220977783], Epoch 26, [2560 / 13374] loss = 3.357679088367149e-05\n",
      "time_elapsed:[26, 5.579927921295166], Epoch 26, [5120 / 13374] loss = 3.7251760659273714e-05\n",
      "time_elapsed:[26, 12.803977251052856], Epoch 26, [7680 / 13374] loss = 3.048302278330084e-05\n",
      "time_elapsed:[26, 19.705159902572632], Epoch 26, [10240 / 13374] loss = 1.6262954886769876e-05\n",
      "time_elapsed:[26, 27.15692901611328], Epoch 26, [12800 / 13374] loss = 7.951421139296144e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.910 %\n",
      "\n",
      "time_elapsed:[26, 40.51285099983215], Epoch 27, [2560 / 13374] loss = 6.007570118526928e-05\n",
      "time_elapsed:[26, 47.369309425354004], Epoch 27, [5120 / 13374] loss = 2.220814349129796e-05\n",
      "time_elapsed:[26, 55.73324513435364], Epoch 27, [7680 / 13374] loss = 2.050783223239705e-05\n",
      "time_elapsed:[27, 4.727789640426636], Epoch 27, [10240 / 13374] loss = 1.1168635865033139e-05\n",
      "time_elapsed:[27, 13.767074823379517], Epoch 27, [12800 / 13374] loss = 1.586815415066667e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.836 %\n",
      "\n",
      "time_elapsed:[27, 34.71376991271973], Epoch 28, [2560 / 13374] loss = 6.142453639768064e-05\n",
      "time_elapsed:[27, 41.73365116119385], Epoch 28, [5120 / 13374] loss = 2.91319920506794e-05\n",
      "time_elapsed:[27, 48.73010063171387], Epoch 28, [7680 / 13374] loss = 1.3037432836426888e-05\n",
      "time_elapsed:[27, 54.000314712524414], Epoch 28, [10240 / 13374] loss = 9.404625416209456e-06\n",
      "time_elapsed:[28, 0.8952710628509521], Epoch 28, [12800 / 13374] loss = 1.3321018741407897e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.940 %\n",
      "\n",
      "time_elapsed:[28, 14.494606256484985], Epoch 29, [2560 / 13374] loss = 2.7089703507954255e-05\n",
      "time_elapsed:[28, 21.390450716018677], Epoch 29, [5120 / 13374] loss = 2.5232197003788315e-05\n",
      "time_elapsed:[28, 28.637805938720703], Epoch 29, [7680 / 13374] loss = 9.571376722306013e-06\n",
      "time_elapsed:[28, 34.373244285583496], Epoch 29, [10240 / 13374] loss = 1.8384893337497488e-05\n",
      "time_elapsed:[28, 40.8088059425354], Epoch 29, [12800 / 13374] loss = 1.079660614777822e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.955 %\n",
      "\n",
      "time_elapsed:[28, 48.91385817527771], Epoch 30, [2560 / 13374] loss = 2.3014992621028796e-05\n",
      "time_elapsed:[28, 53.337207078933716], Epoch 30, [5120 / 13374] loss = 2.0370360289234668e-05\n",
      "time_elapsed:[28, 57.99934768676758], Epoch 30, [7680 / 13374] loss = 1.3396931535680778e-05\n",
      "time_elapsed:[29, 2.4406776428222656], Epoch 30, [10240 / 13374] loss = 1.3691806998394895e-05\n",
      "time_elapsed:[29, 6.516843557357788], Epoch 30, [12800 / 13374] loss = 1.2836387213610578e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.672 %\n",
      "\n",
      "time_elapsed:[29, 14.907024621963501], Epoch 31, [2560 / 13374] loss = 4.983007238479331e-05\n",
      "time_elapsed:[29, 19.116502285003662], Epoch 31, [5120 / 13374] loss = 3.318234303151257e-05\n",
      "time_elapsed:[29, 23.152657985687256], Epoch 31, [7680 / 13374] loss = 1.1283661478955764e-05\n",
      "time_elapsed:[29, 27.877745389938354], Epoch 31, [10240 / 13374] loss = 1.0004229807236698e-05\n",
      "time_elapsed:[29, 32.210376262664795], Epoch 31, [12800 / 13374] loss = 1.28964184114011e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.015 %\n",
      "\n",
      "time_elapsed:[29, 40.239983558654785], Epoch 32, [2560 / 13374] loss = 6.121753540355712e-05\n",
      "time_elapsed:[29, 44.50393295288086], Epoch 32, [5120 / 13374] loss = 2.8607950298464857e-05\n",
      "time_elapsed:[29, 48.77553153038025], Epoch 32, [7680 / 13374] loss = 1.6497164324391633e-05\n",
      "time_elapsed:[29, 53.0474009513855], Epoch 32, [10240 / 13374] loss = 8.047623850870878e-06\n",
      "time_elapsed:[29, 57.28640389442444], Epoch 32, [12800 / 13374] loss = 1.2200486708024982e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.134 %\n",
      "\n",
      "time_elapsed:[30, 5.386545896530151], Epoch 33, [2560 / 13374] loss = 4.899598934571259e-05\n",
      "time_elapsed:[30, 10.224890947341919], Epoch 33, [5120 / 13374] loss = 2.8915994334965944e-05\n",
      "time_elapsed:[30, 14.318797588348389], Epoch 33, [7680 / 13374] loss = 1.4555155757989269e-05\n",
      "time_elapsed:[30, 18.80306077003479], Epoch 33, [10240 / 13374] loss = 1.6319805581588298e-05\n",
      "time_elapsed:[30, 23.27928113937378], Epoch 33, [12800 / 13374] loss = 9.760147804627195e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.015 %\n",
      "\n",
      "time_elapsed:[30, 30.969330072402954], Epoch 34, [2560 / 13374] loss = 4.836918742512353e-05\n",
      "time_elapsed:[30, 35.45254325866699], Epoch 34, [5120 / 13374] loss = 1.2123202395741828e-05\n",
      "time_elapsed:[30, 39.796234130859375], Epoch 34, [7680 / 13374] loss = 1.5226682080538012e-05\n",
      "time_elapsed:[30, 44.49578809738159], Epoch 34, [10240 / 13374] loss = 1.5674482710892335e-05\n",
      "time_elapsed:[30, 48.726109981536865], Epoch 34, [12800 / 13374] loss = 8.569096280552913e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.776 %\n",
      "\n",
      "time_elapsed:[30, 56.48814535140991], Epoch 35, [2560 / 13374] loss = 4.5917062379885465e-05\n",
      "time_elapsed:[31, 0.8293883800506592], Epoch 35, [5120 / 13374] loss = 1.8813352653523907e-05\n",
      "time_elapsed:[31, 5.332136631011963], Epoch 35, [7680 / 13374] loss = 9.974618478736375e-06\n",
      "time_elapsed:[31, 9.923441886901855], Epoch 35, [10240 / 13374] loss = 1.5504376278840937e-05\n",
      "time_elapsed:[31, 14.059203386306763], Epoch 35, [12800 / 13374] loss = 8.921705557440873e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.179 %\n",
      "\n",
      "time_elapsed:[31, 21.919101238250732], Epoch 36, [2560 / 13374] loss = 3.899179500876926e-05\n",
      "time_elapsed:[31, 26.451569080352783], Epoch 36, [5120 / 13374] loss = 1.1013157745765056e-05\n",
      "time_elapsed:[31, 30.70469617843628], Epoch 36, [7680 / 13374] loss = 1.4286673831520602e-05\n",
      "time_elapsed:[31, 35.05415678024292], Epoch 36, [10240 / 13374] loss = 1.6063570001279004e-05\n",
      "time_elapsed:[31, 39.46883726119995], Epoch 36, [12800 / 13374] loss = 6.95557173457928e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.642 %\n",
      "\n",
      "time_elapsed:[31, 47.37633752822876], Epoch 37, [2560 / 13374] loss = 2.5331502911285497e-05\n",
      "time_elapsed:[31, 51.87053394317627], Epoch 37, [5120 / 13374] loss = 2.0249954104656354e-05\n",
      "time_elapsed:[31, 56.31470227241516], Epoch 37, [7680 / 13374] loss = 1.714664904284291e-05\n",
      "time_elapsed:[32, 1.3536603450775146], Epoch 37, [10240 / 13374] loss = 7.567713510070462e-06\n",
      "time_elapsed:[32, 5.442715644836426], Epoch 37, [12800 / 13374] loss = 1.1407599231461063e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.821 %\n",
      "\n",
      "time_elapsed:[32, 13.521536588668823], Epoch 38, [2560 / 13374] loss = 1.4888736586726736e-05\n",
      "time_elapsed:[32, 17.735610008239746], Epoch 38, [5120 / 13374] loss = 6.85247596265981e-06\n",
      "time_elapsed:[32, 22.077980995178223], Epoch 38, [7680 / 13374] loss = 1.595462344994303e-05\n",
      "time_elapsed:[32, 26.59516978263855], Epoch 38, [10240 / 13374] loss = 1.4346439456858207e-05\n",
      "time_elapsed:[32, 31.045943021774292], Epoch 38, [12800 / 13374] loss = 1.0046218449133448e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.881 %\n",
      "\n",
      "time_elapsed:[32, 39.74451160430908], Epoch 39, [2560 / 13374] loss = 2.6642039301805198e-05\n",
      "time_elapsed:[32, 44.487348556518555], Epoch 39, [5120 / 13374] loss = 2.373895222262945e-05\n",
      "time_elapsed:[32, 49.839958906173706], Epoch 39, [7680 / 13374] loss = 1.0517254850128666e-05\n",
      "time_elapsed:[32, 54.218360900878906], Epoch 39, [10240 / 13374] loss = 1.185309338325169e-05\n",
      "time_elapsed:[32, 58.7887864112854], Epoch 39, [12800 / 13374] loss = 4.158827778155683e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.612 %\n",
      "\n",
      "time_elapsed:[33, 6.863105535507202], Epoch 40, [2560 / 13374] loss = 2.1182115233386867e-05\n",
      "time_elapsed:[33, 11.273902416229248], Epoch 40, [5120 / 13374] loss = 1.1541763342393097e-05\n",
      "time_elapsed:[33, 15.714142560958862], Epoch 40, [7680 / 13374] loss = 1.0333911632187665e-05\n",
      "time_elapsed:[33, 20.17209029197693], Epoch 40, [10240 / 13374] loss = 1.07095411294722e-05\n",
      "time_elapsed:[33, 24.795440435409546], Epoch 40, [12800 / 13374] loss = 9.366106496599969e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.104 %\n",
      "\n",
      "time_elapsed:[33, 33.11768865585327], Epoch 41, [2560 / 13374] loss = 3.295548594905995e-05\n",
      "time_elapsed:[33, 37.7790367603302], Epoch 41, [5120 / 13374] loss = 1.7352318536723033e-05\n",
      "time_elapsed:[33, 42.2494113445282], Epoch 41, [7680 / 13374] loss = 1.4124222616374027e-05\n",
      "time_elapsed:[33, 46.61029267311096], Epoch 41, [10240 / 13374] loss = 1.1427257049945183e-05\n",
      "time_elapsed:[33, 50.81337285041809], Epoch 41, [12800 / 13374] loss = 4.216659363009967e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.179 %\n",
      "\n",
      "time_elapsed:[33, 58.87731671333313], Epoch 42, [2560 / 13374] loss = 2.5532533982186578e-05\n",
      "time_elapsed:[34, 3.385554075241089], Epoch 42, [5120 / 13374] loss = 5.213813892623875e-06\n",
      "time_elapsed:[34, 7.668290615081787], Epoch 42, [7680 / 13374] loss = 1.3397813745541498e-05\n",
      "time_elapsed:[34, 12.051829099655151], Epoch 42, [10240 / 13374] loss = 7.893314432294574e-06\n",
      "time_elapsed:[34, 16.598785877227783], Epoch 42, [12800 / 13374] loss = 1.5480525689781643e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.731 %\n",
      "\n",
      "time_elapsed:[34, 24.597894430160522], Epoch 43, [2560 / 13374] loss = 2.8459870009100996e-05\n",
      "time_elapsed:[34, 29.239652156829834], Epoch 43, [5120 / 13374] loss = 1.7529511751490645e-05\n",
      "time_elapsed:[34, 33.63100504875183], Epoch 43, [7680 / 13374] loss = 1.2801911907445174e-05\n",
      "time_elapsed:[34, 38.084128618240356], Epoch 43, [10240 / 13374] loss = 1.1701415132847615e-05\n",
      "time_elapsed:[34, 42.474698543548584], Epoch 43, [12800 / 13374] loss = 7.556654963991605e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.940 %\n",
      "\n",
      "time_elapsed:[34, 50.452824115753174], Epoch 44, [2560 / 13374] loss = 6.173966539790854e-05\n",
      "time_elapsed:[34, 54.62841558456421], Epoch 44, [5120 / 13374] loss = 1.5319066733354703e-05\n",
      "time_elapsed:[34, 59.0222704410553], Epoch 44, [7680 / 13374] loss = 9.387900718138553e-06\n",
      "time_elapsed:[35, 3.6238863468170166], Epoch 44, [10240 / 13374] loss = 1.08360445665312e-05\n",
      "time_elapsed:[35, 8.1261305809021], Epoch 44, [12800 / 13374] loss = 6.628401024499908e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.836 %\n",
      "\n",
      "time_elapsed:[35, 16.410443782806396], Epoch 45, [2560 / 13374] loss = 3.5769342503044754e-05\n",
      "time_elapsed:[35, 20.83451223373413], Epoch 45, [5120 / 13374] loss = 1.2110710486012977e-05\n",
      "time_elapsed:[35, 24.977463960647583], Epoch 45, [7680 / 13374] loss = 1.619760223547928e-05\n",
      "time_elapsed:[35, 29.664788722991943], Epoch 45, [10240 / 13374] loss = 1.2432607945811469e-05\n",
      "time_elapsed:[35, 34.06039595603943], Epoch 45, [12800 / 13374] loss = 9.81829271040624e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.687 %\n",
      "\n",
      "time_elapsed:[35, 42.09300637245178], Epoch 46, [2560 / 13374] loss = 4.974051989847794e-05\n",
      "time_elapsed:[35, 46.64321827888489], Epoch 46, [5120 / 13374] loss = 1.794476884242613e-05\n",
      "time_elapsed:[35, 50.87407875061035], Epoch 46, [7680 / 13374] loss = 3.6938990888302214e-06\n",
      "time_elapsed:[35, 55.272315979003906], Epoch 46, [10240 / 13374] loss = 9.602092177374288e-06\n",
      "time_elapsed:[35, 59.59433722496033], Epoch 46, [12800 / 13374] loss = 1.0586803909973241e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.955 %\n",
      "\n",
      "time_elapsed:[36, 8.127871036529541], Epoch 47, [2560 / 13374] loss = 3.811909118667245e-05\n",
      "time_elapsed:[36, 12.876950025558472], Epoch 47, [5120 / 13374] loss = 2.586591654107906e-05\n",
      "time_elapsed:[36, 17.077046632766724], Epoch 47, [7680 / 13374] loss = 3.4304991913813865e-06\n",
      "time_elapsed:[36, 21.368228673934937], Epoch 47, [10240 / 13374] loss = 1.0619462045724504e-05\n",
      "time_elapsed:[36, 25.707862377166748], Epoch 47, [12800 / 13374] loss = 8.026635441638064e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.075 %\n",
      "\n",
      "time_elapsed:[36, 34.04949712753296], Epoch 48, [2560 / 13374] loss = 3.0687369871884584e-05\n",
      "time_elapsed:[36, 38.43559002876282], Epoch 48, [5120 / 13374] loss = 1.8484899555915035e-05\n",
      "time_elapsed:[36, 43.36889362335205], Epoch 48, [7680 / 13374] loss = 1.2923699614475481e-05\n",
      "time_elapsed:[36, 47.95542883872986], Epoch 48, [10240 / 13374] loss = 1.662579961703159e-05\n",
      "time_elapsed:[36, 52.65506100654602], Epoch 48, [12800 / 13374] loss = 5.849480658071116e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.881 %\n",
      "\n",
      "time_elapsed:[37, 1.0788745880126953], Epoch 49, [2560 / 13374] loss = 2.3053449694998562e-05\n",
      "time_elapsed:[37, 5.352083683013916], Epoch 49, [5120 / 13374] loss = 1.950602927536238e-05\n",
      "time_elapsed:[37, 9.736398696899414], Epoch 49, [7680 / 13374] loss = 1.2027167940686923e-05\n",
      "time_elapsed:[37, 13.743358612060547], Epoch 49, [10240 / 13374] loss = 4.382397492008749e-06\n",
      "time_elapsed:[37, 18.23094940185547], Epoch 49, [12800 / 13374] loss = 1.4389586795005016e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.791 %\n",
      "\n",
      "time_elapsed:[37, 25.964725732803345], Epoch 50, [2560 / 13374] loss = 2.130398752342444e-05\n",
      "time_elapsed:[37, 30.326184034347534], Epoch 50, [5120 / 13374] loss = 1.3811944882036187e-05\n",
      "time_elapsed:[37, 34.894901514053345], Epoch 50, [7680 / 13374] loss = 1.597509799466934e-05\n",
      "time_elapsed:[37, 39.17592692375183], Epoch 50, [10240 / 13374] loss = 6.584791208297247e-06\n",
      "time_elapsed:[37, 43.556565046310425], Epoch 50, [12800 / 13374] loss = 6.58097087580245e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.881 %\n",
      "\n",
      "time_elapsed:[37, 51.70559549331665], Epoch 51, [2560 / 13374] loss = 2.0969033357687294e-05\n",
      "time_elapsed:[37, 56.25989603996277], Epoch 51, [5120 / 13374] loss = 1.576505383127369e-05\n",
      "time_elapsed:[38, 0.4380650520324707], Epoch 51, [7680 / 13374] loss = 1.4013829968462233e-05\n",
      "time_elapsed:[38, 4.801467180252075], Epoch 51, [10240 / 13374] loss = 1.2418002370395698e-05\n",
      "time_elapsed:[38, 9.28149962425232], Epoch 51, [12800 / 13374] loss = 3.1531310469290474e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.701 %\n",
      "\n",
      "time_elapsed:[38, 17.26243233680725], Epoch 52, [2560 / 13374] loss = 2.395081719441805e-05\n",
      "time_elapsed:[38, 21.31475257873535], Epoch 52, [5120 / 13374] loss = 1.852052446338348e-05\n",
      "time_elapsed:[38, 25.83723473548889], Epoch 52, [7680 / 13374] loss = 1.6991072698147036e-05\n",
      "time_elapsed:[38, 31.2713041305542], Epoch 52, [10240 / 13374] loss = 1.4123409528110642e-05\n",
      "time_elapsed:[38, 36.47829794883728], Epoch 52, [12800 / 13374] loss = 7.276924861798761e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.896 %\n",
      "\n",
      "time_elapsed:[38, 44.65832471847534], Epoch 53, [2560 / 13374] loss = 3.6784098483622074e-05\n",
      "time_elapsed:[38, 49.1138219833374], Epoch 53, [5120 / 13374] loss = 8.770142812863924e-06\n",
      "time_elapsed:[38, 53.464436769485474], Epoch 53, [7680 / 13374] loss = 8.023675036383793e-06\n",
      "time_elapsed:[38, 57.821778535842896], Epoch 53, [10240 / 13374] loss = 1.1211877790628932e-05\n",
      "time_elapsed:[39, 2.0579171180725098], Epoch 53, [12800 / 13374] loss = 4.1551834328856785e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.881 %\n",
      "\n",
      "time_elapsed:[39, 9.883747339248657], Epoch 54, [2560 / 13374] loss = 3.456654667388648e-05\n",
      "time_elapsed:[39, 14.66141939163208], Epoch 54, [5120 / 13374] loss = 1.4574002307199407e-05\n",
      "time_elapsed:[39, 18.98295545578003], Epoch 54, [7680 / 13374] loss = 1.3350289918889757e-05\n",
      "time_elapsed:[39, 23.59379529953003], Epoch 54, [10240 / 13374] loss = 1.4249315427150577e-05\n",
      "time_elapsed:[39, 27.99835968017578], Epoch 54, [12800 / 13374] loss = 7.863078280934133e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.925 %\n",
      "\n",
      "time_elapsed:[39, 36.21617817878723], Epoch 55, [2560 / 13374] loss = 2.5472254492342472e-05\n",
      "time_elapsed:[39, 40.5335259437561], Epoch 55, [5120 / 13374] loss = 1.711309960228391e-05\n",
      "time_elapsed:[39, 45.78681564331055], Epoch 55, [7680 / 13374] loss = 2.1106623535160907e-05\n",
      "time_elapsed:[39, 50.61370396614075], Epoch 55, [10240 / 13374] loss = 7.87756926001748e-06\n",
      "time_elapsed:[39, 54.89687490463257], Epoch 55, [12800 / 13374] loss = 6.243305961106671e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.910 %\n",
      "\n",
      "time_elapsed:[40, 2.7324490547180176], Epoch 56, [2560 / 13374] loss = 3.467081842245534e-05\n",
      "time_elapsed:[40, 7.184406995773315], Epoch 56, [5120 / 13374] loss = 2.2487052774522454e-05\n",
      "time_elapsed:[40, 11.510404109954834], Epoch 56, [7680 / 13374] loss = 1.7040787497535348e-05\n",
      "time_elapsed:[40, 15.752235651016235], Epoch 56, [10240 / 13374] loss = 6.664688498858595e-06\n",
      "time_elapsed:[40, 20.282979249954224], Epoch 56, [12800 / 13374] loss = 8.345102287421469e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.104 %\n",
      "\n",
      "time_elapsed:[40, 28.876396417617798], Epoch 57, [2560 / 13374] loss = 3.084319178014994e-05\n",
      "time_elapsed:[40, 32.94349908828735], Epoch 57, [5120 / 13374] loss = 1.216389864566736e-05\n",
      "time_elapsed:[40, 37.279194593429565], Epoch 57, [7680 / 13374] loss = 1.5610206901328638e-05\n",
      "time_elapsed:[40, 41.840731382369995], Epoch 57, [10240 / 13374] loss = 1.3434930224320851e-05\n",
      "time_elapsed:[40, 46.143675327301025], Epoch 57, [12800 / 13374] loss = 5.765059540863149e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.090 %\n",
      "\n",
      "time_elapsed:[40, 53.96071982383728], Epoch 58, [2560 / 13374] loss = 1.3478012988343835e-05\n",
      "time_elapsed:[40, 58.44112586975098], Epoch 58, [5120 / 13374] loss = 1.577165676280856e-05\n",
      "time_elapsed:[41, 2.7218117713928223], Epoch 58, [7680 / 13374] loss = 1.2404412700561807e-05\n",
      "time_elapsed:[41, 7.053241491317749], Epoch 58, [10240 / 13374] loss = 1.0389331691840198e-05\n",
      "time_elapsed:[41, 11.3968825340271], Epoch 58, [12800 / 13374] loss = 6.800624760217033e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.776 %\n",
      "\n",
      "time_elapsed:[41, 21.151237726211548], Epoch 59, [2560 / 13374] loss = 2.3046039132168517e-05\n",
      "time_elapsed:[41, 25.471054553985596], Epoch 59, [5120 / 13374] loss = 1.4042621842236258e-05\n",
      "time_elapsed:[41, 29.89559555053711], Epoch 59, [7680 / 13374] loss = 8.133482879202347e-06\n",
      "time_elapsed:[41, 34.14184093475342], Epoch 59, [10240 / 13374] loss = 1.1747100870707072e-05\n",
      "time_elapsed:[41, 38.498531103134155], Epoch 59, [12800 / 13374] loss = 6.634152214246569e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.851 %\n",
      "\n",
      "time_elapsed:[41, 46.372703075408936], Epoch 60, [2560 / 13374] loss = 1.6720437997719273e-05\n",
      "time_elapsed:[41, 50.63263916969299], Epoch 60, [5120 / 13374] loss = 1.0325181392545346e-05\n",
      "time_elapsed:[41, 55.29987382888794], Epoch 60, [7680 / 13374] loss = 9.144509022007696e-06\n",
      "time_elapsed:[41, 59.70472192764282], Epoch 60, [10240 / 13374] loss = 8.473050002066884e-06\n",
      "time_elapsed:[42, 4.052674770355225], Epoch 60, [12800 / 13374] loss = 6.889703399792779e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.955 %\n",
      "\n",
      "time_elapsed:[42, 12.3678457736969], Epoch 61, [2560 / 13374] loss = 3.4965189115609974e-05\n",
      "time_elapsed:[42, 16.674471378326416], Epoch 61, [5120 / 13374] loss = 1.8499380530556664e-05\n",
      "time_elapsed:[42, 20.97379183769226], Epoch 61, [7680 / 13374] loss = 1.130639975599479e-05\n",
      "time_elapsed:[42, 25.105883598327637], Epoch 61, [10240 / 13374] loss = 9.904793841997162e-06\n",
      "time_elapsed:[42, 29.66618800163269], Epoch 61, [12800 / 13374] loss = 4.929809165332699e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.970 %\n",
      "\n",
      "time_elapsed:[42, 37.65286588668823], Epoch 62, [2560 / 13374] loss = 1.9393319234950468e-05\n",
      "time_elapsed:[42, 41.81027388572693], Epoch 62, [5120 / 13374] loss = 1.7424661564291455e-05\n",
      "time_elapsed:[42, 46.00581455230713], Epoch 62, [7680 / 13374] loss = 1.2357238119875547e-05\n",
      "time_elapsed:[42, 50.56030535697937], Epoch 62, [10240 / 13374] loss = 1.0623652087815572e-05\n",
      "time_elapsed:[42, 55.1034791469574], Epoch 62, [12800 / 13374] loss = 9.214746569341514e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.134 %\n",
      "\n",
      "time_elapsed:[43, 3.313722610473633], Epoch 63, [2560 / 13374] loss = 3.584186561056413e-05\n",
      "time_elapsed:[43, 7.738637208938599], Epoch 63, [5120 / 13374] loss = 1.4049171113583725e-05\n",
      "time_elapsed:[43, 12.224150896072388], Epoch 63, [7680 / 13374] loss = 1.1997466572211124e-05\n",
      "time_elapsed:[43, 16.47924566268921], Epoch 63, [10240 / 13374] loss = 9.610158485884313e-06\n",
      "time_elapsed:[43, 20.652349948883057], Epoch 63, [12800 / 13374] loss = 7.424298473779345e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.701 %\n",
      "\n",
      "time_elapsed:[43, 28.8111412525177], Epoch 64, [2560 / 13374] loss = 3.0855164368404076e-05\n",
      "time_elapsed:[43, 32.810521602630615], Epoch 64, [5120 / 13374] loss = 1.705216163827572e-05\n",
      "time_elapsed:[43, 36.990901947021484], Epoch 64, [7680 / 13374] loss = 4.37520566265448e-06\n",
      "time_elapsed:[43, 41.44150161743164], Epoch 64, [10240 / 13374] loss = 5.769693871116033e-06\n",
      "time_elapsed:[43, 46.04516959190369], Epoch 64, [12800 / 13374] loss = 4.849508513871115e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.104 %\n",
      "\n",
      "time_elapsed:[43, 53.944607973098755], Epoch 65, [2560 / 13374] loss = 3.78217882825993e-05\n",
      "time_elapsed:[43, 58.24609732627869], Epoch 65, [5120 / 13374] loss = 1.1123461263196077e-05\n",
      "time_elapsed:[44, 2.475043535232544], Epoch 65, [7680 / 13374] loss = 2.2188924049260095e-05\n",
      "time_elapsed:[44, 6.63854718208313], Epoch 65, [10240 / 13374] loss = 7.907880899438169e-06\n",
      "time_elapsed:[44, 10.892586469650269], Epoch 65, [12800 / 13374] loss = 7.379685939667979e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.045 %\n",
      "\n",
      "time_elapsed:[44, 18.84090781211853], Epoch 66, [2560 / 13374] loss = 2.1785610442748293e-05\n",
      "time_elapsed:[44, 23.248831033706665], Epoch 66, [5120 / 13374] loss = 1.884537050500512e-05\n",
      "time_elapsed:[44, 27.476118564605713], Epoch 66, [7680 / 13374] loss = 1.2236951079103164e-05\n",
      "time_elapsed:[44, 31.880470991134644], Epoch 66, [10240 / 13374] loss = 9.531877367408015e-06\n",
      "time_elapsed:[44, 36.43984532356262], Epoch 66, [12800 / 13374] loss = 5.747086106566712e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.821 %\n",
      "\n",
      "time_elapsed:[44, 44.164581060409546], Epoch 67, [2560 / 13374] loss = 3.228044442948885e-05\n",
      "time_elapsed:[44, 48.59811592102051], Epoch 67, [5120 / 13374] loss = 9.957084330380894e-06\n",
      "time_elapsed:[44, 52.71826529502869], Epoch 67, [7680 / 13374] loss = 7.384588570857886e-06\n",
      "time_elapsed:[44, 57.07975649833679], Epoch 67, [10240 / 13374] loss = 9.144504474534187e-06\n",
      "time_elapsed:[45, 1.3122661113739014], Epoch 67, [12800 / 13374] loss = 5.210669314692495e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.104 %\n",
      "\n",
      "time_elapsed:[45, 9.586607933044434], Epoch 68, [2560 / 13374] loss = 3.417859988985583e-05\n",
      "time_elapsed:[45, 14.128291606903076], Epoch 68, [5120 / 13374] loss = 1.5810481272637844e-05\n",
      "time_elapsed:[45, 18.23503279685974], Epoch 68, [7680 / 13374] loss = 1.0244819350191392e-05\n",
      "time_elapsed:[45, 22.586750030517578], Epoch 68, [10240 / 13374] loss = 1.0700323400669731e-05\n",
      "time_elapsed:[45, 30.544508457183838], Epoch 68, [12800 / 13374] loss = 9.902188139676582e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.910 %\n",
      "\n",
      "time_elapsed:[45, 46.01185488700867], Epoch 69, [2560 / 13374] loss = 2.5349960196763277e-05\n",
      "time_elapsed:[45, 53.554311990737915], Epoch 69, [5120 / 13374] loss = 1.3199138265918009e-05\n",
      "time_elapsed:[46, 0.45983409881591797], Epoch 69, [7680 / 13374] loss = 1.6015508663258515e-05\n",
      "time_elapsed:[46, 7.469656944274902], Epoch 69, [10240 / 13374] loss = 1.0438043318572454e-05\n",
      "time_elapsed:[46, 13.853290796279907], Epoch 69, [12800 / 13374] loss = 1.0237574315397069e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.925 %\n",
      "\n",
      "time_elapsed:[46, 28.943151235580444], Epoch 70, [2560 / 13374] loss = 2.797857450786978e-05\n",
      "time_elapsed:[46, 35.94731283187866], Epoch 70, [5120 / 13374] loss = 1.2015219908789732e-05\n",
      "time_elapsed:[46, 43.603816509246826], Epoch 70, [7680 / 13374] loss = 1.4448397450905759e-05\n",
      "time_elapsed:[46, 51.26196026802063], Epoch 70, [10240 / 13374] loss = 6.964523890928831e-06\n",
      "time_elapsed:[46, 58.815380334854126], Epoch 70, [12800 / 13374] loss = 7.4120880526606925e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.104 %\n",
      "\n",
      "time_elapsed:[47, 14.148358583450317], Epoch 71, [2560 / 13374] loss = 3.859807475237176e-05\n",
      "time_elapsed:[47, 23.380046129226685], Epoch 71, [5120 / 13374] loss = 1.3081473298370838e-05\n",
      "time_elapsed:[47, 32.241326093673706], Epoch 71, [7680 / 13374] loss = 1.2140519174863584e-05\n",
      "time_elapsed:[47, 40.442739963531494], Epoch 71, [10240 / 13374] loss = 1.3951968867331743e-05\n",
      "time_elapsed:[47, 47.88348865509033], Epoch 71, [12800 / 13374] loss = 9.24662163015455e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.000 %\n",
      "\n",
      "time_elapsed:[48, 19.4501793384552], Epoch 72, [2560 / 13374] loss = 2.4286879124701954e-05\n",
      "time_elapsed:[48, 35.149537801742554], Epoch 72, [5120 / 13374] loss = 1.6914764273678884e-05\n",
      "time_elapsed:[48, 46.607457637786865], Epoch 72, [7680 / 13374] loss = 1.1411219929868821e-05\n",
      "time_elapsed:[48, 59.47470211982727], Epoch 72, [10240 / 13374] loss = 5.2884925025864504e-06\n",
      "time_elapsed:[49, 17.0395827293396], Epoch 72, [12800 / 13374] loss = 1.1269359674770385e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.731 %\n",
      "\n",
      "time_elapsed:[49, 46.50190186500549], Epoch 73, [2560 / 13374] loss = 2.9311157049960457e-05\n",
      "time_elapsed:[50, 8.051261901855469], Epoch 73, [5120 / 13374] loss = 1.0460265002620872e-05\n",
      "time_elapsed:[50, 32.22109293937683], Epoch 73, [7680 / 13374] loss = 1.3590010894404259e-05\n",
      "time_elapsed:[50, 50.66703772544861], Epoch 73, [10240 / 13374] loss = 1.000563679554034e-05\n",
      "time_elapsed:[51, 7.479125022888184], Epoch 73, [12800 / 13374] loss = 9.789949217520189e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.925 %\n",
      "\n",
      "time_elapsed:[51, 40.247398138046265], Epoch 74, [2560 / 13374] loss = 2.1775140339741483e-05\n",
      "time_elapsed:[51, 52.29430556297302], Epoch 74, [5120 / 13374] loss = 1.8822467609425075e-05\n",
      "time_elapsed:[52, 2.73793363571167], Epoch 74, [7680 / 13374] loss = 1.7545169612276368e-05\n",
      "time_elapsed:[52, 15.975563526153564], Epoch 74, [10240 / 13374] loss = 7.8785542427795e-06\n",
      "time_elapsed:[52, 30.93715476989746], Epoch 74, [12800 / 13374] loss = 6.182344350236235e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.149 %\n",
      "\n",
      "time_elapsed:[52, 52.76934862136841], Epoch 75, [2560 / 13374] loss = 3.764775465242565e-05\n",
      "time_elapsed:[53, 8.85623550415039], Epoch 75, [5120 / 13374] loss = 2.7934187528444454e-05\n",
      "time_elapsed:[53, 25.770591974258423], Epoch 75, [7680 / 13374] loss = 6.830605798313627e-06\n",
      "time_elapsed:[53, 40.78551459312439], Epoch 75, [10240 / 13374] loss = 1.5530265955021605e-05\n",
      "time_elapsed:[53, 54.15234851837158], Epoch 75, [12800 / 13374] loss = 6.3822885749686975e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.000 %\n",
      "\n",
      "time_elapsed:[54, 19.649783849716187], Epoch 76, [2560 / 13374] loss = 1.9082264770986512e-05\n",
      "time_elapsed:[54, 37.1759512424469], Epoch 76, [5120 / 13374] loss = 1.1015208656317554e-05\n",
      "time_elapsed:[54, 51.295685052871704], Epoch 76, [7680 / 13374] loss = 7.861742233217228e-06\n",
      "time_elapsed:[55, 11.856513023376465], Epoch 76, [10240 / 13374] loss = 1.007431092148181e-05\n",
      "time_elapsed:[55, 25.83702301979065], Epoch 76, [12800 / 13374] loss = 4.22304765379522e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.030 %\n",
      "\n",
      "time_elapsed:[55, 52.08684682846069], Epoch 77, [2560 / 13374] loss = 3.4321248676860705e-05\n",
      "time_elapsed:[56, 6.196265459060669], Epoch 77, [5120 / 13374] loss = 1.6511636204086244e-05\n",
      "time_elapsed:[56, 23.09756374359131], Epoch 77, [7680 / 13374] loss = 9.76296178123448e-06\n",
      "time_elapsed:[56, 47.62737011909485], Epoch 77, [10240 / 13374] loss = 4.935025117447367e-06\n",
      "time_elapsed:[57, 16.689044952392578], Epoch 77, [12800 / 13374] loss = 1.145926580647938e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.015 %\n",
      "\n",
      "time_elapsed:[57, 38.154271364212036], Epoch 78, [2560 / 13374] loss = 2.1832871425431222e-05\n",
      "time_elapsed:[57, 51.4547016620636], Epoch 78, [5120 / 13374] loss = 2.1258299966575578e-05\n",
      "time_elapsed:[57, 57.802398920059204], Epoch 78, [7680 / 13374] loss = 8.458698175672907e-06\n",
      "time_elapsed:[58, 4.9260900020599365], Epoch 78, [10240 / 13374] loss = 9.52354366745567e-06\n",
      "time_elapsed:[58, 12.104465246200562], Epoch 78, [12800 / 13374] loss = 8.152590453391895e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.045 %\n",
      "\n",
      "time_elapsed:[58, 23.371986389160156], Epoch 79, [2560 / 13374] loss = 3.089245728915557e-05\n",
      "time_elapsed:[58, 30.441736459732056], Epoch 79, [5120 / 13374] loss = 1.7514943465357646e-05\n",
      "time_elapsed:[58, 38.072667360305786], Epoch 79, [7680 / 13374] loss = 1.7193891835631803e-05\n",
      "time_elapsed:[58, 45.00687551498413], Epoch 79, [10240 / 13374] loss = 1.65079200087348e-05\n",
      "time_elapsed:[58, 51.84599685668945], Epoch 79, [12800 / 13374] loss = 4.325909230828984e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.090 %\n",
      "\n",
      "time_elapsed:[59, 6.256985187530518], Epoch 80, [2560 / 13374] loss = 2.5829835067270324e-05\n",
      "time_elapsed:[59, 13.350078582763672], Epoch 80, [5120 / 13374] loss = 1.7005102563416585e-05\n",
      "time_elapsed:[59, 19.034037590026855], Epoch 80, [7680 / 13374] loss = 8.2617061707424e-06\n",
      "time_elapsed:[59, 26.230443000793457], Epoch 80, [10240 / 13374] loss = 7.1707472670823336e-06\n",
      "time_elapsed:[59, 35.45268487930298], Epoch 80, [12800 / 13374] loss = 7.1589038270758465e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.701 %\n",
      "\n",
      "time_elapsed:[59, 47.812817335128784], Epoch 81, [2560 / 13374] loss = 3.072470644838177e-05\n",
      "time_elapsed:[59, 55.30486726760864], Epoch 81, [5120 / 13374] loss = 1.4234739865059964e-05\n",
      "time_elapsed:[60, 2.254767417907715], Epoch 81, [7680 / 13374] loss = 6.059233328414848e-06\n",
      "time_elapsed:[60, 8.144116163253784], Epoch 81, [10240 / 13374] loss = 1.3440799193631392e-05\n",
      "time_elapsed:[60, 14.748032808303833], Epoch 81, [12800 / 13374] loss = 8.04008959676139e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.119 %\n",
      "\n",
      "time_elapsed:[60, 50.552978515625], Epoch 82, [2560 / 13374] loss = 2.1751435269834474e-05\n",
      "time_elapsed:[61, 3.199159860610962], Epoch 82, [5120 / 13374] loss = 2.2395837731892243e-05\n",
      "time_elapsed:[61, 11.400779962539673], Epoch 82, [7680 / 13374] loss = 6.512747404485708e-06\n",
      "time_elapsed:[61, 24.265477180480957], Epoch 82, [10240 / 13374] loss = 1.3919093362346757e-05\n",
      "time_elapsed:[61, 37.40566611289978], Epoch 82, [12800 / 13374] loss = 6.6371512730256654e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.015 %\n",
      "\n",
      "time_elapsed:[62, 5.3520495891571045], Epoch 83, [2560 / 13374] loss = 2.751050669758115e-05\n",
      "time_elapsed:[62, 16.802923917770386], Epoch 83, [5120 / 13374] loss = 1.593557135493029e-05\n",
      "time_elapsed:[62, 30.2431001663208], Epoch 83, [7680 / 13374] loss = 1.0267252946505323e-05\n",
      "time_elapsed:[62, 36.31471133232117], Epoch 83, [10240 / 13374] loss = 6.7712571762967855e-06\n",
      "time_elapsed:[62, 42.62444996833801], Epoch 83, [12800 / 13374] loss = 5.7246752476203255e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.940 %\n",
      "\n",
      "time_elapsed:[62, 54.02393937110901], Epoch 84, [2560 / 13374] loss = 1.5509811419178732e-05\n",
      "time_elapsed:[63, 0.7932167053222656], Epoch 84, [5120 / 13374] loss = 1.8606671801535413e-05\n",
      "time_elapsed:[63, 9.545194387435913], Epoch 84, [7680 / 13374] loss = 9.903367754304782e-06\n",
      "time_elapsed:[63, 16.808379411697388], Epoch 84, [10240 / 13374] loss = 4.1488551687507425e-06\n",
      "time_elapsed:[63, 25.816509008407593], Epoch 84, [12800 / 13374] loss = 7.085538982209982e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.224 %\n",
      "\n",
      "time_elapsed:[63, 41.83636260032654], Epoch 85, [2560 / 13374] loss = 3.772902346099727e-05\n",
      "time_elapsed:[63, 50.53243446350098], Epoch 85, [5120 / 13374] loss = 1.736988269840367e-05\n",
      "time_elapsed:[63, 57.30400800704956], Epoch 85, [7680 / 13374] loss = 8.081223313638475e-06\n",
      "time_elapsed:[64, 3.6997299194335938], Epoch 85, [10240 / 13374] loss = 1.1639385775197297e-05\n",
      "time_elapsed:[64, 9.339508295059204], Epoch 85, [12800 / 13374] loss = 6.036743798176758e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.791 %\n",
      "\n",
      "time_elapsed:[64, 18.621542930603027], Epoch 86, [2560 / 13374] loss = 1.4214524526323657e-05\n",
      "time_elapsed:[64, 24.494868993759155], Epoch 86, [5120 / 13374] loss = 2.3277141735889018e-05\n",
      "time_elapsed:[64, 31.82978129386902], Epoch 86, [7680 / 13374] loss = 8.915877515391912e-06\n",
      "time_elapsed:[64, 41.248011112213135], Epoch 86, [10240 / 13374] loss = 7.816326615284197e-06\n",
      "time_elapsed:[64, 47.5303475856781], Epoch 86, [12800 / 13374] loss = 9.42450606089551e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.015 %\n",
      "\n",
      "time_elapsed:[64, 56.76766085624695], Epoch 87, [2560 / 13374] loss = 1.5373459973488934e-05\n",
      "time_elapsed:[65, 2.348249673843384], Epoch 87, [5120 / 13374] loss = 1.3685125850315671e-05\n",
      "time_elapsed:[65, 8.534376859664917], Epoch 87, [7680 / 13374] loss = 7.634890607732814e-06\n",
      "time_elapsed:[65, 14.96916913986206], Epoch 87, [10240 / 13374] loss = 6.511875653814059e-06\n",
      "time_elapsed:[65, 21.283891916275024], Epoch 87, [12800 / 13374] loss = 5.664043328579282e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.060 %\n",
      "\n",
      "time_elapsed:[65, 31.862507820129395], Epoch 88, [2560 / 13374] loss = 2.7622478228295222e-05\n",
      "time_elapsed:[65, 37.352044343948364], Epoch 88, [5120 / 13374] loss = 1.1087715392932296e-05\n",
      "time_elapsed:[65, 44.871992349624634], Epoch 88, [7680 / 13374] loss = 1.116400926548522e-05\n",
      "time_elapsed:[65, 51.77880001068115], Epoch 88, [10240 / 13374] loss = 6.646630936302245e-06\n",
      "time_elapsed:[65, 58.566115617752075], Epoch 88, [12800 / 13374] loss = 5.21196943736868e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.970 %\n",
      "\n",
      "time_elapsed:[66, 10.49537444114685], Epoch 89, [2560 / 13374] loss = 3.313940760563128e-05\n",
      "time_elapsed:[66, 17.001728057861328], Epoch 89, [5120 / 13374] loss = 1.6065361705841497e-05\n",
      "time_elapsed:[66, 22.041772603988647], Epoch 89, [7680 / 13374] loss = 8.766828614170663e-06\n",
      "time_elapsed:[66, 28.62025761604309], Epoch 89, [10240 / 13374] loss = 4.534254003374372e-06\n",
      "time_elapsed:[66, 35.729623556137085], Epoch 89, [12800 / 13374] loss = 4.7064154387044255e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.015 %\n",
      "\n",
      "time_elapsed:[66, 48.06572675704956], Epoch 90, [2560 / 13374] loss = 2.773878259176854e-05\n",
      "time_elapsed:[66, 54.661638498306274], Epoch 90, [5120 / 13374] loss = 1.269641325052362e-05\n",
      "time_elapsed:[67, 1.0587058067321777], Epoch 90, [7680 / 13374] loss = 7.966507837409154e-06\n",
      "time_elapsed:[67, 7.948407173156738], Epoch 90, [10240 / 13374] loss = 9.518802471575327e-06\n",
      "time_elapsed:[67, 14.058567523956299], Epoch 90, [12800 / 13374] loss = 1.074999545380706e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.985 %\n",
      "\n",
      "time_elapsed:[67, 24.097814798355103], Epoch 91, [2560 / 13374] loss = 2.4533637770218775e-05\n",
      "time_elapsed:[67, 29.332517623901367], Epoch 91, [5120 / 13374] loss = 1.3821690117765684e-05\n",
      "time_elapsed:[67, 36.05097937583923], Epoch 91, [7680 / 13374] loss = 6.1725500017928425e-06\n",
      "time_elapsed:[67, 42.64285206794739], Epoch 91, [10240 / 13374] loss = 7.3686824180185795e-06\n",
      "time_elapsed:[67, 49.5002818107605], Epoch 91, [12800 / 13374] loss = 1.2385011359583586e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 84.134 %\n",
      "\n",
      "time_elapsed:[68, 0.5764718055725098], Epoch 92, [2560 / 13374] loss = 2.5725923478603363e-05\n",
      "time_elapsed:[68, 6.890034437179565], Epoch 92, [5120 / 13374] loss = 1.9057401004829444e-05\n",
      "time_elapsed:[68, 12.56720232963562], Epoch 92, [7680 / 13374] loss = 7.54441271055839e-06\n",
      "time_elapsed:[68, 18.84859299659729], Epoch 92, [10240 / 13374] loss = 6.158946689538425e-06\n",
      "time_elapsed:[68, 24.787704944610596], Epoch 92, [12800 / 13374] loss = 7.717290827713441e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.761 %\n",
      "\n",
      "time_elapsed:[68, 34.32502198219299], Epoch 93, [2560 / 13374] loss = 3.134601138299331e-05\n",
      "time_elapsed:[68, 40.899271726608276], Epoch 93, [5120 / 13374] loss = 2.1509464204427786e-05\n",
      "time_elapsed:[68, 47.301151514053345], Epoch 93, [7680 / 13374] loss = 9.835454875428695e-06\n",
      "time_elapsed:[68, 53.84194374084473], Epoch 93, [10240 / 13374] loss = 1.1439474292274099e-05\n",
      "time_elapsed:[69, 0.30010294914245605], Epoch 93, [12800 / 13374] loss = 9.919802323565818e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.731 %\n",
      "\n",
      "time_elapsed:[69, 10.361632585525513], Epoch 94, [2560 / 13374] loss = 2.45770497713238e-05\n",
      "time_elapsed:[69, 18.27896213531494], Epoch 94, [5120 / 13374] loss = 1.771207280398812e-05\n",
      "time_elapsed:[69, 24.560543298721313], Epoch 94, [7680 / 13374] loss = 8.306316885864362e-06\n",
      "time_elapsed:[69, 30.978843688964844], Epoch 94, [10240 / 13374] loss = 8.748541404202115e-06\n",
      "time_elapsed:[69, 37.16974353790283], Epoch 94, [12800 / 13374] loss = 7.754199032206088e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.701 %\n",
      "\n",
      "time_elapsed:[69, 49.26929330825806], Epoch 95, [2560 / 13374] loss = 2.663621307874564e-05\n",
      "time_elapsed:[69, 54.581329107284546], Epoch 95, [5120 / 13374] loss = 2.7955655241385102e-05\n",
      "time_elapsed:[69, 59.641295194625854], Epoch 95, [7680 / 13374] loss = 1.0187779480475001e-05\n",
      "time_elapsed:[70, 4.964241981506348], Epoch 95, [10240 / 13374] loss = 2.3356444216915406e-05\n",
      "time_elapsed:[70, 11.383802652359009], Epoch 95, [12800 / 13374] loss = 2.28203662118176e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.224 %\n",
      "\n",
      "time_elapsed:[70, 25.425966024398804], Epoch 96, [2560 / 13374] loss = 5.517702811630443e-05\n",
      "time_elapsed:[70, 34.36144757270813], Epoch 96, [5120 / 13374] loss = 2.372841481701471e-05\n",
      "time_elapsed:[70, 39.581563234329224], Epoch 96, [7680 / 13374] loss = 1.543644793855492e-05\n",
      "time_elapsed:[70, 44.9034640789032], Epoch 96, [10240 / 13374] loss = 1.5626199456164613e-05\n",
      "time_elapsed:[70, 50.02178168296814], Epoch 96, [12800 / 13374] loss = 1.7183663658215664e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 82.970 %\n",
      "\n",
      "time_elapsed:[70, 58.04108500480652], Epoch 97, [2560 / 13374] loss = 5.546019019675441e-05\n",
      "time_elapsed:[71, 2.2128257751464844], Epoch 97, [5120 / 13374] loss = 2.4408762328675948e-05\n",
      "time_elapsed:[71, 7.760624170303345], Epoch 97, [7680 / 13374] loss = 2.510928243282251e-05\n",
      "time_elapsed:[71, 12.614532709121704], Epoch 97, [10240 / 13374] loss = 1.2770353350788355e-05\n",
      "time_elapsed:[71, 17.453744411468506], Epoch 97, [12800 / 13374] loss = 7.320937584154308e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.746 %\n",
      "\n",
      "time_elapsed:[71, 25.868455171585083], Epoch 98, [2560 / 13374] loss = 6.098194353398867e-05\n",
      "time_elapsed:[71, 31.06101131439209], Epoch 98, [5120 / 13374] loss = 2.2278622054727748e-05\n",
      "time_elapsed:[71, 35.328397274017334], Epoch 98, [7680 / 13374] loss = 1.4667759387521073e-05\n",
      "time_elapsed:[71, 40.25862431526184], Epoch 98, [10240 / 13374] loss = 7.77718196331989e-06\n",
      "time_elapsed:[71, 45.272727251052856], Epoch 98, [12800 / 13374] loss = 1.1109980732726399e-05\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.672 %\n",
      "\n",
      "time_elapsed:[71, 53.68930387496948], Epoch 99, [2560 / 13374] loss = 2.431748725939542e-05\n",
      "time_elapsed:[71, 58.972571849823], Epoch 99, [5120 / 13374] loss = 1.6896932720555924e-05\n",
      "time_elapsed:[72, 3.1644041538238525], Epoch 99, [7680 / 13374] loss = 9.810082701733336e-06\n",
      "time_elapsed:[72, 7.488290309906006], Epoch 99, [10240 / 13374] loss = 1.0456350537424441e-05\n",
      "time_elapsed:[72, 12.766587972640991], Epoch 99, [12800 / 13374] loss = 5.620594038191484e-06\n",
      "====evaluating trained model...(is testing)\n",
      "Accuracy on name-country test set is 83.701 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import gzip\n",
    "import csv\n",
    "from torch.nn.utils.rnn import pack_padded_sequence  # 导入pack_padded_sequence()方法\n",
    "\n",
    "\n",
    "'''输出共18种语言'''\n",
    "\n",
    "'''模型主要由embedding layer, GRU和Linear layer构成'''\n",
    "\n",
    "# parameters\n",
    "NUM_CHARS = 128        # 输入字符集，用128字典长度\n",
    "HIDDEN_SIZE = 100      # 隐层100维\n",
    "NUM_COUNTRIES = 18\n",
    "NUM_LAYERS = 2         # GRU用2层\n",
    "USE_GPU = False         # GPU使用\n",
    "NUM_EPOCHS = 100       # 本实验25个epoch就可以了\n",
    "BATCH_SIZE = 256       # BATCH_SIZE为256\n",
    "\n",
    "\n",
    "'''1.Prepare data 构建数据集类'''\n",
    "class NameDataset(Dataset):\n",
    "    # 初始化\n",
    "    def __init__(self, is_training_set = True):\n",
    "        # super(NameDataset, self).__init__()\n",
    "        # 根据是否是训练集来选择文件名\n",
    "        filename = \"names_train.csv.gz\" if is_training_set else \"names_test.csv.gz\"\n",
    "        # 用到gzip包和csv包来从.gz文件中读取data\n",
    "        with gzip.open(filename, 'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader) # rows列表中每一个元素都是数据集中的一行（name+country）（元组 ）\n",
    "        # 处理name\n",
    "        self.name_list = [row[0] for row in rows] # 每一行的第0个元素是name\n",
    "        self.len = len(self.name_list) # 记录数据集的大小（样本的总数目）\n",
    "        # 处理country    \n",
    "        self.orgin_country_list = [row[1] for row in rows] # 每一行的第1个元素是country，orgin_country_list中的country是有重复的，无序的\n",
    "        self.country_list = list(sorted(set(self.orgin_country_list))) # set列表变集合（去除重复元素），排序，注意：country_list中的country没有重复，并且是有序的（字典序）\n",
    "        self.country_dict = self.getCountryDict() # 调用函数getCountryDict()获得country_dict，字典中key:country; value:index ex: 0,1,2...\n",
    "        self.num_countries = len(self.country_dict) # country的种类数，是输出维度\n",
    "        \n",
    "    # 根据下标获得数据集中的某一个样本信息[name+country在字典中的索引]\n",
    "    def __getitem__(self, index): # （方法是以怎样的形式获取数据集）\n",
    "        return self.name_list[index], self.country_dict[self.orgin_country_list[index]] # 返回name字符串和country对应的字典下标\n",
    "               # 输入样本，\n",
    "\n",
    "    # 获得数据集大小\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # 获得country字典 （键：country, 值：字典序的下标）\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict() # 初始化字典\n",
    "        # 将list转化为dict\n",
    "        for index, country in enumerate(self.country_list, 0): # index从0开始\n",
    "            country_dict[country] = index # 键：country, 值：字典序的下标\n",
    "        return country_dict\n",
    "    \n",
    "    # 根据字典下标获得country\n",
    "    def index2country(self, index):\n",
    "        return self.country_dict[index]\n",
    "    \n",
    "    # 获得数据集中country的种类数\n",
    "    def getCountriesNum(self):\n",
    "        return self.num_countries\n",
    "    \n",
    "\n",
    "# 根据tensor是否迁移到GPU上 返回tensor\n",
    "def createTensor(tensor):\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        tensor = tensor.to(device) # tensor移动到GPU上\n",
    "    return tensor\n",
    "\n",
    "'''2. Design model'''\n",
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 1, bidirectional = True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        \n",
    "        # embedding\n",
    "        # input size: (seq_len, batch_size)\n",
    "        # output size: (seq_len, batch_size, hidden_size)\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)     # 构造嵌入层\n",
    "        # GRU\n",
    "        # INPUTS: input size: (seq_len, batch_size, hidden_size)\n",
    "        # INPUTS: hidden size: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        # OUTPUTS: output size: (seq_len, batch_size, hidden_size * num_directions)\n",
    "        # OUTPUTS: hidden size: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, num_layers, bidirectional = bidirectional) # bidirectional单向还是双向\n",
    "        # Linear(Fully Connected layer)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.num_directions, output_size)\n",
    "        \n",
    "    def initHidden(self, batch_size): # 根据输入batch_size，构成一个全0的hidden张量\n",
    "        hidden = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size)   #（层*是否双向 batch_size hidden_size）\n",
    "        return createTensor(hidden)\n",
    "    \n",
    "    def forward(self, input, seq_lengths):\n",
    "        input = input.t() # 将input转置 batch_size * seq_len --> seq_len * batch_size\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        hidden = self.initHidden(batch_size) # init hidden 0\n",
    "        \n",
    "        # embedding layer\n",
    "        embedding = self.embedding(input) # embedding size: batch_size, seq_len, embedding_size\n",
    "        \n",
    "        # GRU\n",
    "        gru_input = pack_padded_sequence(embedding, seq_lengths) # pack_padded_sequence，将输入转化为size为seq_len, batch_size, hidden_size的tensor\n",
    "            # 返回一个PackedSequence对象        \n",
    "            # 第2个参数：一个tensor， 是每个batch element的长度列表\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        if self.num_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim = 1) # GRU为双向时，hidden = [前向的第n个hidden, 反向的第n个hidden] 连接\n",
    "        else:\n",
    "            hidden_cat = hidden[-1] # GRU为单向时，hidden = 前向的第n个hidden\n",
    "            \n",
    "        # fully connected layer\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output\n",
    "\n",
    "## convert name to tensor\n",
    "# 必须sort the batch element by length of sequence(降序)\n",
    "# name -> characters -> ASCII值 -> padding -> （transpose） ->sort\n",
    "    \n",
    "# 将某个name转换为相应的字符对应的ASCII码值的列表  \"Alice\" -> ['A','l','i','c','e'] -> [65 108 105 99 101]\n",
    "def name2ASCIIlist(name):\n",
    "    ASCIIlist = [ord(char) for char in name] # ord(char)获取char的ASCII码值\n",
    "    return ASCIIlist\n",
    "    \n",
    "def makeTensors(name_list, country_list):\n",
    "    ## 获得每个name的码值列表，然后得到所有码值列表的列表 \n",
    "    name_sequences = [name2ASCIIlist(name) for name in name_list] # name -> characters_list -> ASCII值_list\n",
    "    name_seq_lens = [len(name_ASCII) for name_ASCII in name_sequences] # 每个姓名ASCII序列的长度的列表\n",
    "    # 数值类型转换\n",
    "    name_seq_lens = torch.LongTensor(name_seq_lens)\n",
    "    country_list = country_list.long()\n",
    "    \n",
    "    ## padding   make tensor of name, BatchSize * SeqLen \n",
    "    # 先构造一个（dataset.len, max(name_seq_len)）大小的全0张量\n",
    "    name_tensor = torch.zeros(len(name_sequences), name_seq_lens.max()).long()\n",
    "    # 然后将每个name_sequence填到全0张量中\n",
    "    for index, (name_sequence, name_seq_len) in enumerate(zip(name_sequences, name_seq_lens), 0):\n",
    "        name_tensor[index, 0:name_seq_len] = torch.LongTensor(name_sequence) # 第index行的第0列到第len(name_seq)列 填入 name_sequence\n",
    "    \n",
    "    ## sort by length of name_sequence to use pack_padded_sequence\n",
    "    ordered_name_seq_lens, len_indexes = name_seq_lens.sort(dim = 0, descending = True) # 首先将name_seq_lens降序排序，len_indexes是它在原tensor中的索引\n",
    "    ordered_name_tensor = name_tensor[len_indexes] # 按照新的下标更新name_tensor\n",
    "    ordered_country_list = country_list[len_indexes] # 同步更新country_list中的值\n",
    "    \n",
    "    ## 返回转化后的name tensor, name's length tensor and country_list tensor\n",
    "    return createTensor(ordered_name_tensor), createTensor(ordered_name_seq_lens), createTensor(ordered_country_list) \n",
    "    \n",
    "    \n",
    "'''3. Training and Test'''\n",
    "def train():  # 每个epoch的训练过程\n",
    "    loss = 0.0\n",
    "    for batch_index, (names, countries) in enumerate(train_loader, 0): # 每一次取出一个batch中的所有样本\n",
    "        ## 对于每一个batch中的所有样本，做如下操作：\n",
    "        # forward\n",
    "        inputs, seq_lens, targets = makeTensors(names, countries) \n",
    "        outputs = classifier_model(inputs, seq_lens)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss += loss.item()\n",
    "        \n",
    "        if batch_index % 10 == 9: # 每10个batch输出一次信息\n",
    "            print(f'time_elapsed:{timePassed(start_time)}, Epoch {epoch}, ', end = '') # 输出经过的时间和epoch\n",
    "            print(f'[{(batch_index+1) * len(inputs)} / {len(training_set)}] ', end = '') # 已经训练过的样本数/总样本数，用来表示训练进度\n",
    "            print(f'loss = {loss / ((batch_index+1) * len(inputs))}') # loss求均值\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total_samples = len(test_set)\n",
    "    print(\"====evaluating trained model...(is testing)\")\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(test_loader, 0):\n",
    "            inputs, seq_lens, targets = makeTensors(names, countries)\n",
    "            outputs = classifier_model(inputs, seq_lens)\n",
    "            #country_pred = torch.max(output, dim = 1)\n",
    "            country_preds = outputs.max(dim = 1, keepdim = True)[1]\n",
    "            #correct += (country_pred == target).sum().item()\n",
    "            correct += country_preds.eq(targets.view_as(country_preds)).sum().item()\n",
    "        accuracy = correct / total_samples\n",
    "        print('Accuracy on name-country test set is %.3f %%\\n' % (100 * accuracy)) # 化为百分数\n",
    "    return accuracy\n",
    "        \n",
    "\n",
    "## 计算经过的时间\n",
    "def timePassed(start_time): # 参数：开始时间\n",
    "    time_passed = time.time() - start_time # 经过的时间，返回以秒为单位\n",
    "    # 换算为分和秒\n",
    "    minute = math.floor(time_passed / 60) # 取下整\n",
    "    second = time_passed - minute * 60    # 剩多少秒 \n",
    "    return [minute, second] # 返回值：几分几秒\n",
    "\n",
    "\n",
    "'''4. Main cycle'''\n",
    "if __name__ == '__main__':\n",
    "    # 数据准备\n",
    "    training_set = NameDataset(is_training_set = True)\n",
    "    train_loader = DataLoader(dataset = training_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    test_set = NameDataset(is_training_set = False)\n",
    "    test_loader = DataLoader(dataset = test_set, batch_size = BATCH_SIZE, shuffle = False)\n",
    "        \n",
    "    NUM_COUNTRIES = training_set.getCountriesNum()  # 给NUM_COUNTRIES赋值   总的类别数量\n",
    "    \n",
    "    # 定义模型对象\n",
    "    classifier_model = RNNClassifier(NUM_CHARS, HIDDEN_SIZE, NUM_COUNTRIES, NUM_LAYERS) # input_size, hidden_size, output_size, num_layers  创建分类器\n",
    "    if USE_GPU: # 是否用GPU训练模型\n",
    "        device = torch.device(\"cuda:0\") # 申请GPU cuda:0\n",
    "        classifier_model.to(device)     # 将模型迁移到GPU上\n",
    "    \n",
    "    # 构建loss function和optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier_model.parameters(), lr = 0.001)\n",
    "    \n",
    "    # training and test\n",
    "    start_time = time.time() # 开始时间\n",
    "    print(\"The num of total training epochs is %d. \" % NUM_EPOCHS)\n",
    "    accuracy_list = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train()\n",
    "        accuracy = test()\n",
    "        accuracy_list.append(accuracy)\n",
    "    \n",
    "\n",
    "    # 作图 epoch-accuracy\n",
    "    epoch_list = np.arange(1, NUM_EPOCHS + 1, 1) # epoch从1到NUM_EPOCHS\n",
    "    accuracy_list = np.array(accuracy_list)\n",
    "    plt.plot(epoch_list, accuracy_list)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
